{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024e68cd",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook implements an ASD (Autism Spectrum Disorder) prediction model using the Xception model. The dataset is organized into `train`, `valid`, and `test` folders, each with subfolders `Autistics` and `Non_Autistics`. The goal is to achieve ~91% accuracy, as reported in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3a2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a1962",
   "metadata": {},
   "source": [
    "## Set Random Seed\n",
    "We set a random seed to ensure reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf70d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24361bf0",
   "metadata": {},
   "source": [
    "## Define Dataset Paths\n",
    "Specify the paths to the dataset folders. Update `base_dir` to match the location of your dataset on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8f05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to dataset\n",
    "base_dir = 'data'  # Update this to your dataset path\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c74f0a",
   "metadata": {},
   "source": [
    "## Set Image Parameters\n",
    "Define the image size, batch size, and number of classes for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8284f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_SIZE = (299, 299)  # Xception default input size\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2  # Autistics vs. Non_Autistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a520c3",
   "metadata": {},
   "source": [
    "## Data Augmentation and Preprocessing\n",
    "Set up data generators to preprocess and augment the training images, and preprocess the validation and test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d4759b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Preprocessing for validation and test (no augmentation)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b8ac0",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Load the images from the `train`, `valid`, and `test` folders using the data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a04bdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2540 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training, validation, and testing data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af39638",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "Load the Xception model, freeze its layers, and add custom layers for ASD prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e6d5299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Xception model with pre-trained ImageNet weights\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43925210",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "Compile the model with the Adam optimizer, binary crossentropy loss, and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377d7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3fc927",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "Display the architecture of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e81022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8015f8",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Train the model for 20 epochs using the training data, with validation on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d3114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 3s/step - accuracy: 0.5907 - loss: 0.6640 - val_accuracy: 0.7396 - val_loss: 0.5784\n",
      "Epoch 2/20\n",
      "\u001b[1m 1/79\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:55\u001b[0m 3s/step - accuracy: 0.7188 - loss: 0.5628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 127ms/step - accuracy: 0.7188 - loss: 0.5628 - val_accuracy: 0.7396 - val_loss: 0.5782\n",
      "Epoch 3/20\n",
      "\u001b[1m28/79\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:00\u001b[0m 4s/step - accuracy: 0.7106 - loss: 0.5752"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e35995",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Evaluate the model on the test data to check its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eaa219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1055e",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Save the trained model to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09aece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('xception_asd_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf5f3b9-e5d2-4421-ab02-28090d214d4d",
   "metadata": {},
   "source": [
    "## Load the Saved Model\n",
    "Load the saved Xception model from the `xception_asd_model.h5` file to use it for predictions without retraining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e22d5-c256-4903-af08-a8a08752755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path to the saved model\n",
    "model_path = 'xception_asd_model.h5'  # Update this if the model is in a different directory\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc919b",
   "metadata": {},
   "source": [
    "## Define Prediction Function\n",
    "Define a function to predict ASD from a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fe51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict ASD from a single image\n",
    "def predict_asd(image_path, model):\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    img = image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    label = 'Autistic' if prediction > 0.5 else 'Non_Autistic'\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    return label, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e031dbf",
   "metadata": {},
   "source": [
    "## Make a Prediction\n",
    "Use the prediction function to classify a single image. Update the `image_path` to point to an actual image in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "image_path = './data/test/Autistic/Autistic.7.jpg'  # Update this to a real image path\n",
    "label, confidence = predict_asd(image_path, model)\n",
    "print(f\"Prediction: {label}, Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f89ad5",
   "metadata": {},
   "source": [
    "## Explainable AI with Grad-CAM\n",
    "To understand which parts of the image the model focuses on when making its prediction, we use Grad-CAM (Gradient-weighted Class Activation Mapping). This technique generates a heatmap highlighting the regions of the image that contributed most to the model's decision (e.g., `Autistic` or `Non_Autistic`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34012dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # For image processing and heatmap overlay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411ed56",
   "metadata": {},
   "source": [
    "## Define Grad-CAM Function\n",
    "We define a function to compute the Grad-CAM heatmap for a given image and model. This function identifies the last convolutional layer in the Xception model, computes the gradients, and generates the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradcam_heatmap(model, img_path, img_size=(299, 299), last_conv_layer_name=\"block14_sepconv2_act\"):\n",
    "    \"\"\"\n",
    "    Generate a Grad-CAM heatmap for the given image and model.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model (Xception in this case).\n",
    "        img_path: Path to the image.\n",
    "        img_size: Size to resize the image (default: 299x299 for Xception).\n",
    "        last_conv_layer_name: Name of the last convolutional layer in the model.\n",
    "    \n",
    "    Returns:\n",
    "        heatmap: The Grad-CAM heatmap.\n",
    "        img: The original image.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # Convert img_array to a TensorFlow tensor\n",
    "    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
    "\n",
    "    # Get the last convolutional layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    \n",
    "    # Create a submodel that outputs the last conv layer and the final predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [last_conv_layer.output, model.output]\n",
    "    )\n",
    "\n",
    "    # Compute gradients of the predicted class with respect to the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Watch the input tensor\n",
    "        tape.watch(img_tensor)\n",
    "        # Pass the input as a list to match model.inputs structure\n",
    "        conv_outputs, predictions = grad_model([img_tensor])\n",
    "        # For binary classification, use the prediction directly\n",
    "        predicted_class = tf.cast(predictions > 0.5, \"float32\")\n",
    "        loss = predictions[:, 0] if predicted_class[0] > 0.5 else 1 - predictions[:, 0]\n",
    "\n",
    "    # Get the gradients\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))  # Global average pooling\n",
    "\n",
    "    # Multiply each channel in the feature map by its gradient importance\n",
    "    conv_outputs = conv_outputs[0]  # Remove batch dimension\n",
    "    heatmap = tf.reduce_mean(tf.multiply(conv_outputs, pooled_grads), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)  # ReLU to keep only positive contributions\n",
    "    heatmap = heatmap / np.max(heatmap)  # Normalize to [0, 1]\n",
    "\n",
    "    # Resize heatmap to match the original image size\n",
    "    heatmap = cv2.resize(heatmap, (img_size[1], img_size[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)  # Convert to 0-255 range for visualization\n",
    "\n",
    "    return heatmap, img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcf335",
   "metadata": {},
   "source": [
    "## Visualize the Grad-CAM Heatmap\n",
    "We overlay the Grad-CAM heatmap on the original image to see which regions the model focused on when making its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24070d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same image path as in the prediction\n",
    "# Ensure this matches the image_path you used in the prediction cell\n",
    "image_path = './Autistic.62.jpg'  # Replace with your actual image path\n",
    "\n",
    "# Get the Grad-CAM heatmap\n",
    "heatmap, original_img = get_gradcam_heatmap(model, image_path, img_size=IMG_SIZE)\n",
    "\n",
    "# Convert the heatmap to RGB for overlay\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # Apply JET colormap (blue to red)\n",
    "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
    "\n",
    "# Convert original image to numpy array for overlay\n",
    "original_img = tf.keras.preprocessing.image.img_to_array(original_img)\n",
    "\n",
    "# Resize heatmap to match the original image dimensions\n",
    "heatmap = np.float32(heatmap) / 255\n",
    "alpha = 0.4  # Transparency factor for the heatmap\n",
    "overlay = (1 - alpha) * original_img + alpha * heatmap * 255  # Overlay the heatmap\n",
    "overlay = np.clip(overlay, 0, 255).astype(np.uint8)  # Ensure values are in valid range\n",
    "\n",
    "# Display the original image, heatmap, and overlay\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(original_img.astype(np.uint8))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Heatmap\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Overlay\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Overlay (Original + Heatmap)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the prediction again for reference\n",
    "label, confidence = predict_asd(image_path, model)\n",
    "print(f\"Prediction: {label}, Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85113cd5-c994-430a-ad46-3c9e14930217",
   "metadata": {},
   "source": [
    "## List Test Images and Run Grad-CAM\n",
    "We will list a few images from the `test` dataset (from both `Autistics` and `Non_Autistics` subfolders) and run Grad-CAM to visualize the regions of the images that the model focuses on when making its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b123c7-f530-4504-90f0-a27e45aa301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the test dataset\n",
    "test_dir = 'data/test'  # Update this to your test dataset path\n",
    "\n",
    "# Get paths to images in the Autistics and Non_Autistics subfolders\n",
    "autistic_dir = os.path.join(test_dir, 'Autistic')\n",
    "non_autistic_dir = os.path.join(test_dir, 'Non_Autistic')\n",
    "\n",
    "# List a few images from each subfolder (e.g., first 3 images)\n",
    "autistic_images = [os.path.join(autistic_dir, fname) for fname in os.listdir(autistic_dir)[45:52] if fname.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "non_autistic_images = [os.path.join(non_autistic_dir, fname) for fname in os.listdir(non_autistic_dir)[45:52] if fname.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Combine the lists\n",
    "test_images = autistic_images + non_autistic_images\n",
    "\n",
    "# Print the selected images\n",
    "print(\"Selected test images:\")\n",
    "for img_path in test_images:\n",
    "    print(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419126f-18d1-4e36-a443-f28a25ff7f13",
   "metadata": {},
   "source": [
    "## Run Grad-CAM on Test Images\n",
    "We will run Grad-CAM on the selected test images and display the original image, Grad-CAM heatmap, and overlay for each image, along with the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35315e-248d-4cb7-a022-62fce84f8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the get_gradcam_heatmap and predict_asd functions are defined (they should already be in earlier cells)\n",
    "# Also ensure matplotlib, cv2, and numpy are imported (from the Grad-CAM setup)\n",
    "\n",
    "# Run Grad-CAM on each test image\n",
    "for img_path in test_images:\n",
    "    # Get the Grad-CAM heatmap\n",
    "    heatmap, original_img = get_gradcam_heatmap(model, img_path, img_size=IMG_SIZE)\n",
    "\n",
    "    # Convert the heatmap to RGB for overlay\n",
    "    heatmap_rgb = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # Apply JET colormap (blue to red)\n",
    "    heatmap_rgb = cv2.cvtColor(heatmap_rgb, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n",
    "\n",
    "    # Convert original image to numpy array for overlay\n",
    "    original_img = tf.keras.preprocessing.image.img_to_array(original_img)\n",
    "\n",
    "    # Resize heatmap to match the original image dimensions\n",
    "    heatmap_rgb = np.float32(heatmap_rgb) / 255\n",
    "    alpha = 0.4  # Transparency factor for the heatmap\n",
    "    overlay = (1 - alpha) * original_img + alpha * heatmap_rgb * 255  # Overlay the heatmap\n",
    "    overlay = np.clip(overlay, 0, 255).astype(np.uint8)  # Ensure values are in valid range\n",
    "\n",
    "    # Display the original image, heatmap, and overlay\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original_img.astype(np.uint8))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Heatmap\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap_rgb)\n",
    "    plt.title(\"Grad-CAM Heatmap\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Overlay\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"Overlay (Original + Heatmap)\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Add a super title with the image path\n",
    "    plt.suptitle(f\"Image: {os.path.basename(img_path)}\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Print the prediction\n",
    "    label, confidence = predict_asd(img_path, model)\n",
    "    print(f\"Prediction for {os.path.basename(img_path)}: {label}, Confidence: {confidence:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f3ccf-77ba-446d-a3e3-2b7822cfee1e",
   "metadata": {},
   "source": [
    "## Evaluate Predictions on Selected Test Images\n",
    "We will compare the model's predictions with the true labels for the selected test images to calculate the accuracy on this subset and understand why the predictions might be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f3a1f-43d1-49b9-998e-fcbf84cb1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the true label from the image path\n",
    "def get_true_label(img_path):\n",
    "    if 'Autistics' in img_path:\n",
    "        return 'Autistic'\n",
    "    elif 'Non_Autistics' in img_path:\n",
    "        return 'Non_Autistic'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Evaluate predictions on the selected test images\n",
    "correct_predictions = 0\n",
    "total_images = len(test_images)\n",
    "\n",
    "print(\"Evaluating predictions on selected test images:\")\n",
    "for img_path in test_images:\n",
    "    # Get the true label\n",
    "    true_label = get_true_label(img_path)\n",
    "    \n",
    "    # Get the predicted label\n",
    "    predicted_label, confidence = predict_asd(img_path, model)\n",
    "    \n",
    "    # Check if the prediction is correct\n",
    "    is_correct = (true_label == predicted_label)\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Image: {os.path.basename(img_path)}\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted Label: {predicted_label}, Confidence: {confidence:.2f}\")\n",
    "    print(f\"Correct: {is_correct}\\n\")\n",
    "\n",
    "# Calculate accuracy on this subset\n",
    "subset_accuracy = (correct_predictions / total_images) * 100\n",
    "print(f\"Accuracy on selected test images: {subset_accuracy:.2f}%\")\n",
    "print(f\"Number of correct predictions: {correct_predictions} out of {total_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dcd096-c034-416f-b7d1-6f158de43fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
